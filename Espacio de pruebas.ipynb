{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "os.environ['SPARK_HOME'] = '/home/armando/spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/08/26 20:48:05 WARN Utils: Your hostname, HP resolves to a loopback address: 127.0.1.1; using 172.28.10.209 instead (on interface eth0)\n",
      "23/08/26 20:48:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/26 20:48:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beeline\t\t      pyspark\t       spark-class2.cmd     spark-sql2.cmd\n",
      "beeline.cmd\t      pyspark.cmd      spark-connect-shell  spark-submit\n",
      "docker-image-tool.sh  pyspark2.cmd     spark-shell\t    spark-submit.cmd\n",
      "find-spark-home       run-example      spark-shell.cmd\t    spark-submit2.cmd\n",
      "find-spark-home.cmd   run-example.cmd  spark-shell2.cmd     sparkR\n",
      "load-spark-env.cmd    spark-class      spark-sql\t    sparkR.cmd\n",
      "load-spark-env.sh     spark-class.cmd  spark-sql.cmd\t    sparkR2.cmd\n",
      "23/08/26 20:51:15 WARN Utils: Your hostname, HP resolves to a loopback address: 127.0.1.1; using 172.28.10.209 instead (on interface eth0)\n",
      "23/08/26 20:51:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/08/26 20:51:18 INFO SparkContext: Running Spark version 3.4.1\n",
      "23/08/26 20:51:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/26 20:51:18 INFO ResourceUtils: ==============================================================\n",
      "23/08/26 20:51:18 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "23/08/26 20:51:18 INFO ResourceUtils: ==============================================================\n",
      "23/08/26 20:51:18 INFO SparkContext: Submitted application: PythonMnMCount\n",
      "23/08/26 20:51:18 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "23/08/26 20:51:18 INFO ResourceProfile: Limiting resource is cpu\n",
      "23/08/26 20:51:18 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "23/08/26 20:51:18 INFO SecurityManager: Changing view acls to: armando\n",
      "23/08/26 20:51:18 INFO SecurityManager: Changing modify acls to: armando\n",
      "23/08/26 20:51:18 INFO SecurityManager: Changing view acls groups to: \n",
      "23/08/26 20:51:18 INFO SecurityManager: Changing modify acls groups to: \n",
      "23/08/26 20:51:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: armando; groups with view permissions: EMPTY; users with modify permissions: armando; groups with modify permissions: EMPTY\n",
      "23/08/26 20:51:18 INFO Utils: Successfully started service 'sparkDriver' on port 43083.\n",
      "23/08/26 20:51:18 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/08/26 20:51:19 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/08/26 20:51:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "23/08/26 20:51:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "23/08/26 20:51:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/08/26 20:51:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ada477b4-aa60-4387-b57d-fc0160e6ef92\n",
      "23/08/26 20:51:19 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB\n",
      "23/08/26 20:51:19 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "23/08/26 20:51:19 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "23/08/26 20:51:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/08/26 20:51:19 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "23/08/26 20:51:19 INFO Executor: Starting executor ID driver on host 172.28.10.209\n",
      "23/08/26 20:51:19 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "23/08/26 20:51:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43761.\n",
      "23/08/26 20:51:19 INFO NettyBlockTransferService: Server created on 172.28.10.209:43761\n",
      "23/08/26 20:51:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "23/08/26 20:51:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.28.10.209, 43761, None)\n",
      "23/08/26 20:51:19 INFO BlockManagerMasterEndpoint: Registering block manager 172.28.10.209:43761 with 366.3 MiB RAM, BlockManagerId(driver, 172.28.10.209, 43761, None)\n",
      "23/08/26 20:51:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.28.10.209, 43761, None)\n",
      "23/08/26 20:51:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.28.10.209, 43761, None)\n",
      "23/08/26 20:51:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "23/08/26 20:51:20 INFO SharedState: Warehouse path is 'file:/home/armando/scrap/spark-warehouse'.\n",
      "23/08/26 20:51:22 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.\n",
      "23/08/26 20:51:22 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n",
      "23/08/26 20:51:25 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/08/26 20:51:25 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\n",
      "23/08/26 20:51:26 INFO CodeGenerator: Code generated in 294.193714 ms\n",
      "23/08/26 20:51:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 350.1 KiB, free 366.0 MiB)\n",
      "23/08/26 20:51:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 365.9 MiB)\n",
      "23/08/26 20:51:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.28.10.209:43761 (size: 34.2 KiB, free: 366.3 MiB)\n",
      "23/08/26 20:51:27 INFO SparkContext: Created broadcast 0 from load at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/08/26 20:51:27 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.1 KiB, free 365.9 MiB)\n",
      "23/08/26 20:51:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.9 MiB)\n",
      "23/08/26 20:51:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.28.10.209:43761 (size: 6.0 KiB, free: 366.3 MiB)\n",
      "23/08/26 20:51:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.28.10.209, executor driver, partition 0, PROCESS_LOCAL, 7909 bytes) \n",
      "23/08/26 20:51:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "23/08/26 20:51:27 INFO FileScanRDD: Reading File path: file:///home/armando/data.csv, range: 0-1184873, partition values: [empty row]\n",
      "23/08/26 20:51:27 INFO CodeGenerator: Code generated in 13.91062 ms\n",
      "23/08/26 20:51:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1636 bytes result sent to driver\n",
      "23/08/26 20:51:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 440 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:27 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 0.618 s\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/26 20:51:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "23/08/26 20:51:27 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 0.683310 s\n",
      "23/08/26 20:51:27 INFO CodeGenerator: Code generated in 12.12612 ms\n",
      "23/08/26 20:51:27 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/08/26 20:51:27 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/08/26 20:51:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 350.1 KiB, free 365.6 MiB)\n",
      "23/08/26 20:51:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 365.5 MiB)\n",
      "23/08/26 20:51:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.28.10.209:43761 (size: 34.2 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:27 INFO SparkContext: Created broadcast 2 from load at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/08/26 20:51:28 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Got job 1 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Final stage: ResultStage 1 (load at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 26.0 KiB, free 365.5 MiB)\n",
      "23/08/26 20:51:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 365.5 MiB)\n",
      "23/08/26 20:51:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.28.10.209:43761 (size: 12.2 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.28.10.209, executor driver, partition 0, PROCESS_LOCAL, 7909 bytes) \n",
      "23/08/26 20:51:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "23/08/26 20:51:28 INFO FileScanRDD: Reading File path: file:///home/armando/data.csv, range: 0-1184873, partition values: [empty row]\n",
      "23/08/26 20:51:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.28.10.209:43761 in memory (size: 6.0 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1659 bytes result sent to driver\n",
      "23/08/26 20:51:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 365 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:28 INFO DAGScheduler: ResultStage 1 (load at NativeMethodAccessorImpl.java:0) finished in 0.430 s\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/26 20:51:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Job 1 finished: load at NativeMethodAccessorImpl.java:0, took 0.437677 s\n",
      "23/08/26 20:51:28 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/08/26 20:51:28 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/08/26 20:51:28 INFO CodeGenerator: Code generated in 19.460228 ms\n",
      "23/08/26 20:51:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 350.0 KiB, free 365.2 MiB)\n",
      "23/08/26 20:51:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 365.1 MiB)\n",
      "23/08/26 20:51:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.28.10.209:43761 (size: 34.3 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:28 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/08/26 20:51:28 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.4 KiB, free 365.1 MiB)\n",
      "23/08/26 20:51:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.1 MiB)\n",
      "23/08/26 20:51:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.28.10.209:43761 (size: 7.2 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:28 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.28.10.209, executor driver, partition 0, PROCESS_LOCAL, 7909 bytes) \n",
      "23/08/26 20:51:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "23/08/26 20:51:28 INFO FileScanRDD: Reading File path: file:///home/armando/data.csv, range: 0-1184873, partition values: [empty row]\n",
      "23/08/26 20:51:28 INFO CodeGenerator: Code generated in 12.989192 ms\n",
      "23/08/26 20:51:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1655 bytes result sent to driver\n",
      "23/08/26 20:51:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 66 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:28 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0.081 s\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/26 20:51:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "23/08/26 20:51:28 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0.088709 s\n",
      "23/08/26 20:51:28 INFO CodeGenerator: Code generated in 17.972649 ms\n",
      "+-----+------+-----+\n",
      "|State|Color |Count|\n",
      "+-----+------+-----+\n",
      "|TX   |Red   |20   |\n",
      "|NV   |Blue  |66   |\n",
      "|CO   |Blue  |79   |\n",
      "|OR   |Blue  |71   |\n",
      "|WA   |Yellow|93   |\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/08/26 20:51:28 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/08/26 20:51:28 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/08/26 20:51:29 INFO CodeGenerator: Code generated in 66.527008 ms\n",
      "23/08/26 20:51:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 350.0 KiB, free 364.8 MiB)\n",
      "23/08/26 20:51:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 364.7 MiB)\n",
      "23/08/26 20:51:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.28.10.209:43761 (size: 34.3 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:29 INFO SparkContext: Created broadcast 6 from showString at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Registering RDD 17 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Got map stage job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.4 KiB, free 364.7 MiB)\n",
      "23/08/26 20:51:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 364.7 MiB)\n",
      "23/08/26 20:51:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.28.10.209:43761 (size: 18.6 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:29 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.28.10.209, executor driver, partition 0, PROCESS_LOCAL, 7898 bytes) \n",
      "23/08/26 20:51:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)\n",
      "23/08/26 20:51:29 INFO CodeGenerator: Code generated in 14.836538 ms\n",
      "23/08/26 20:51:29 INFO CodeGenerator: Code generated in 8.36157 ms\n",
      "23/08/26 20:51:29 INFO CodeGenerator: Code generated in 11.225117 ms\n",
      "23/08/26 20:51:29 INFO CodeGenerator: Code generated in 10.620881 ms\n",
      "23/08/26 20:51:29 INFO FileScanRDD: Reading File path: file:///home/armando/data.csv, range: 0-1184873, partition values: [empty row]\n",
      "23/08/26 20:51:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.28.10.209:43761 in memory (size: 34.3 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:29 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.28.10.209:43761 in memory (size: 7.2 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2809 bytes result sent to driver\n",
      "23/08/26 20:51:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 399 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:29 INFO DAGScheduler: ShuffleMapStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.424 s\n",
      "23/08/26 20:51:29 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/08/26 20:51:29 INFO DAGScheduler: running: Set()\n",
      "23/08/26 20:51:29 INFO DAGScheduler: waiting: Set()\n",
      "23/08/26 20:51:29 INFO DAGScheduler: failed: Set()\n",
      "23/08/26 20:51:29 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/08/26 20:51:29 INFO CodeGenerator: Code generated in 18.565611 ms\n",
      "23/08/26 20:51:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "23/08/26 20:51:29 INFO CodeGenerator: Code generated in 18.647928 ms\n",
      "23/08/26 20:51:29 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 41.6 KiB, free 365.0 MiB)\n",
      "23/08/26 20:51:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 365.0 MiB)\n",
      "23/08/26 20:51:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.28.10.209:43761 (size: 19.8 KiB, free: 366.2 MiB)\n",
      "23/08/26 20:51:29 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.28.10.209, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "23/08/26 20:51:29 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)\n",
      "23/08/26 20:51:30 INFO ShuffleBlockFetcherIterator: Getting 1 (4.8 KiB) non-empty blocks including 1 (4.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/08/26 20:51:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms\n",
      "23/08/26 20:51:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 8986 bytes result sent to driver\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 109 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:30 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.123 s\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.147471 s\n",
      "23/08/26 20:51:30 INFO CodeGenerator: Code generated in 13.117217 ms\n",
      "23/08/26 20:51:30 INFO CodeGenerator: Code generated in 11.114975 ms\n",
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|WA   |Green |1779 |\n",
      "|OR   |Orange|1743 |\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1725 |\n",
      "|CA   |Green |1723 |\n",
      "|CO   |Yellow|1721 |\n",
      "|CA   |Brown |1718 |\n",
      "|CO   |Green |1713 |\n",
      "|NV   |Orange|1712 |\n",
      "|TX   |Yellow|1703 |\n",
      "|NV   |Green |1698 |\n",
      "|AZ   |Brown |1698 |\n",
      "|WY   |Green |1695 |\n",
      "|CO   |Blue  |1695 |\n",
      "|NM   |Red   |1690 |\n",
      "|AZ   |Orange|1689 |\n",
      "|NM   |Yellow|1688 |\n",
      "|NM   |Brown |1687 |\n",
      "|UT   |Orange|1684 |\n",
      "|NM   |Green |1682 |\n",
      "|UT   |Red   |1680 |\n",
      "|AZ   |Green |1676 |\n",
      "|NV   |Yellow|1675 |\n",
      "|NV   |Blue  |1673 |\n",
      "|WA   |Red   |1671 |\n",
      "|WY   |Red   |1670 |\n",
      "|WA   |Brown |1669 |\n",
      "|NM   |Orange|1665 |\n",
      "|WY   |Blue  |1664 |\n",
      "|WA   |Yellow|1663 |\n",
      "|WA   |Orange|1658 |\n",
      "|NV   |Brown |1657 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CO   |Brown |1656 |\n",
      "|UT   |Blue  |1655 |\n",
      "|AZ   |Yellow|1654 |\n",
      "|TX   |Orange|1652 |\n",
      "|AZ   |Red   |1648 |\n",
      "|OR   |Blue  |1646 |\n",
      "|UT   |Yellow|1645 |\n",
      "|OR   |Red   |1645 |\n",
      "|CO   |Orange|1642 |\n",
      "|TX   |Brown |1641 |\n",
      "|NM   |Blue  |1638 |\n",
      "|AZ   |Blue  |1636 |\n",
      "|OR   |Green |1634 |\n",
      "|UT   |Brown |1631 |\n",
      "|WY   |Yellow|1626 |\n",
      "|WA   |Blue  |1625 |\n",
      "|CO   |Red   |1624 |\n",
      "|OR   |Brown |1621 |\n",
      "|TX   |Blue  |1614 |\n",
      "|OR   |Yellow|1614 |\n",
      "|NV   |Red   |1610 |\n",
      "|CA   |Blue  |1603 |\n",
      "|WY   |Orange|1595 |\n",
      "|UT   |Green |1591 |\n",
      "|WY   |Brown |1532 |\n",
      "+-----+------+-----+\n",
      "\n",
      "23/08/26 20:51:30 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/08/26 20:51:30 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/08/26 20:51:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "23/08/26 20:51:30 INFO CodeGenerator: Code generated in 16.140576 ms\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 350.0 KiB, free 364.7 MiB)\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 364.6 MiB)\n",
      "23/08/26 20:51:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.28.10.209:43761 (size: 34.3 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:30 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Registering RDD 25 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[25] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 23.8 KiB, free 364.6 MiB)\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 364.6 MiB)\n",
      "23/08/26 20:51:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.28.10.209:43761 (size: 11.4 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[25] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.28.10.209, executor driver, partition 0, PROCESS_LOCAL, 7898 bytes) \n",
      "23/08/26 20:51:30 INFO Executor: Running task 0.0 in stage 6.0 (TID 5)\n",
      "23/08/26 20:51:30 INFO CodeGenerator: Code generated in 6.175187 ms\n",
      "23/08/26 20:51:30 INFO FileScanRDD: Reading File path: file:///home/armando/data.csv, range: 0-1184873, partition values: [empty row]\n",
      "23/08/26 20:51:30 INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 2723 bytes result sent to driver\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 274 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:30 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.287 s\n",
      "23/08/26 20:51:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/08/26 20:51:30 INFO DAGScheduler: running: Set()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: waiting: Set()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: failed: Set()\n",
      "23/08/26 20:51:30 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/08/26 20:51:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "23/08/26 20:51:30 INFO CodeGenerator: Code generated in 19.470539 ms\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Registering RDD 28 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 39.8 KiB, free 364.6 MiB)\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 364.6 MiB)\n",
      "23/08/26 20:51:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.28.10.209:43761 (size: 18.7 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:30 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.28.10.209, executor driver, partition 0, NODE_LOCAL, 7352 bytes) \n",
      "23/08/26 20:51:30 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)\n",
      "23/08/26 20:51:30 INFO ShuffleBlockFetcherIterator: Getting 1 (4.5 KiB) non-empty blocks including 1 (4.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/08/26 20:51:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "23/08/26 20:51:30 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 5596 bytes result sent to driver\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 28 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:30 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.043 s\n",
      "23/08/26 20:51:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/08/26 20:51:30 INFO DAGScheduler: running: Set()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: waiting: Set()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: failed: Set()\n",
      "23/08/26 20:51:30 INFO CodeGenerator: Code generated in 10.324677 ms\n",
      "23/08/26 20:51:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 12.1 KiB, free 364.5 MiB)\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 364.5 MiB)\n",
      "23/08/26 20:51:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.28.10.209:43761 (size: 5.8 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:30 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (172.28.10.209, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "23/08/26 20:51:30 INFO Executor: Running task 0.0 in stage 11.0 (TID 7)\n",
      "23/08/26 20:51:30 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/08/26 20:51:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "23/08/26 20:51:30 INFO Executor: Finished task 0.0 in stage 11.0 (TID 7). 3995 bytes result sent to driver\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 14 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:30 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.022 s\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.028757 s\n",
      "Total Rows = 60\n",
      "23/08/26 20:51:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(State),EqualTo(State,CA)\n",
      "23/08/26 20:51:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(State#17),(State#17 = CA)\n",
      "23/08/26 20:51:30 INFO CodeGenerator: Code generated in 32.829984 ms\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 350.0 KiB, free 364.2 MiB)\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 364.2 MiB)\n",
      "23/08/26 20:51:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.28.10.209:43761 (size: 34.3 KiB, free: 366.0 MiB)\n",
      "23/08/26 20:51:30 INFO SparkContext: Created broadcast 13 from showString at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Registering RDD 35 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 3\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Got map stage job 8 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[35] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 41.0 KiB, free 364.1 MiB)\n",
      "23/08/26 20:51:30 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 364.1 MiB)\n",
      "23/08/26 20:51:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.28.10.209:43761 (size: 19.2 KiB, free: 366.0 MiB)\n",
      "23/08/26 20:51:30 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[35] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:30 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:30 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (172.28.10.209, executor driver, partition 0, PROCESS_LOCAL, 7898 bytes) \n",
      "23/08/26 20:51:30 INFO Executor: Running task 0.0 in stage 12.0 (TID 8)\n",
      "23/08/26 20:51:30 INFO FileScanRDD: Reading File path: file:///home/armando/data.csv, range: 0-1184873, partition values: [empty row]\n",
      "23/08/26 20:51:31 INFO CodeGenerator: Code generated in 6.242546 ms\n",
      "23/08/26 20:51:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.28.10.209:43761 in memory (size: 34.3 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:31 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.28.10.209:43761 in memory (size: 11.4 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:31 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.28.10.209:43761 in memory (size: 5.8 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:31 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.28.10.209:43761 in memory (size: 18.7 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:31 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.28.10.209:43761 in memory (size: 19.8 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:31 INFO Executor: Finished task 0.0 in stage 12.0 (TID 8). 2822 bytes result sent to driver\n",
      "23/08/26 20:51:31 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 181 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:31 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:31 INFO DAGScheduler: ShuffleMapStage 12 (showString at NativeMethodAccessorImpl.java:0) finished in 0.194 s\n",
      "23/08/26 20:51:31 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/08/26 20:51:31 INFO DAGScheduler: running: Set()\n",
      "23/08/26 20:51:31 INFO DAGScheduler: waiting: Set()\n",
      "23/08/26 20:51:31 INFO DAGScheduler: failed: Set()\n",
      "23/08/26 20:51:31 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/08/26 20:51:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "23/08/26 20:51:31 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Got job 9 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Final stage: ResultStage 14 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[39] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/08/26 20:51:31 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 43.2 KiB, free 364.6 MiB)\n",
      "23/08/26 20:51:31 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 364.6 MiB)\n",
      "23/08/26 20:51:31 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.28.10.209:43761 (size: 20.6 KiB, free: 366.1 MiB)\n",
      "23/08/26 20:51:31 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[39] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/26 20:51:31 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "23/08/26 20:51:31 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 9) (172.28.10.209, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "23/08/26 20:51:31 INFO Executor: Running task 0.0 in stage 14.0 (TID 9)\n",
      "23/08/26 20:51:31 INFO ShuffleBlockFetcherIterator: Getting 1 (537.0 B) non-empty blocks including 1 (537.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/08/26 20:51:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "23/08/26 20:51:31 INFO Executor: Finished task 0.0 in stage 14.0 (TID 9). 5515 bytes result sent to driver\n",
      "23/08/26 20:51:31 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 9) in 19 ms on 172.28.10.209 (executor driver) (1/1)\n",
      "23/08/26 20:51:31 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "23/08/26 20:51:31 INFO DAGScheduler: ResultStage 14 (showString at NativeMethodAccessorImpl.java:0) finished in 0.030 s\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/26 20:51:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished\n",
      "23/08/26 20:51:31 INFO DAGScheduler: Job 9 finished: showString at NativeMethodAccessorImpl.java:0, took 0.036853 s\n",
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|CA   |Green |1723 |\n",
      "|CA   |Brown |1718 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CA   |Blue  |1603 |\n",
      "+-----+------+-----+\n",
      "\n",
      "23/08/26 20:51:31 INFO SparkContext: Invoking stop() from shutdown hook\n",
      "23/08/26 20:51:31 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "23/08/26 20:51:31 INFO SparkUI: Stopped Spark web UI at http://172.28.10.209:4041\n",
      "23/08/26 20:51:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "23/08/26 20:51:31 INFO MemoryStore: MemoryStore cleared\n",
      "23/08/26 20:51:31 INFO BlockManager: BlockManager stopped\n",
      "23/08/26 20:51:31 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "23/08/26 20:51:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "23/08/26 20:51:31 INFO SparkContext: Successfully stopped SparkContext\n",
      "23/08/26 20:51:31 INFO ShutdownHookManager: Shutdown hook called\n",
      "23/08/26 20:51:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-8a3efc8b-7218-4f1d-8f45-72d963711c12\n",
      "23/08/26 20:51:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-c3813f41-1626-40b3-9f9a-22d3b65f87eb/pyspark-ebae79af-4cc6-49a3-8d98-a979abf17e19\n",
      "23/08/26 20:51:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-c3813f41-1626-40b3-9f9a-22d3b65f87eb\n"
     ]
    }
   ],
   "source": [
    "!ls ../spark/bin\n",
    "!../spark/bin/spark-submit ../codeExample.py ../data.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
